
"""
Reflection Agentå®žçŽ° - è‡ªæˆ‘åæ€ä¸Žè¿­ä»£ä¼˜åŒ–çš„æ™ºèƒ½ä½“




1. what?


2. æ ¹æ®å›žç­”å†…å®¹æ‰¾å‡ºå¯èƒ½å‡ºé—®é¢˜åœ°æ–¹

3. æ ¹æ®åé¦ˆæ„è§ä¿®æ”¹å›žç­”



"""

from typing import Optional, Dict, Any
import logging
from ..core.agent import Agent
from ..core.llm_client import LlmClient
from ..core.message import Message
from ..core.config import Config

logger = logging.getLogger(__name__)


DEFAULT_PROMPTS = {
    "initial": """
è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚å®Œæˆä»»åŠ¡:

ä»»åŠ¡: {task}

è¯·æä¾›ä¸€ä¸ªå®Œæ•´ã€å‡†ç¡®çš„å›žç­”ã€‚
""",
    "reflect": """
è¯·ä»”ç»†å®¡æŸ¥ä»¥ä¸‹å›žç­”ï¼Œå¹¶æ‰¾å‡ºå¯èƒ½çš„é—®é¢˜æˆ–æ”¹è¿›ç©ºé—´:

# åŽŸå§‹ä»»åŠ¡:
{task}

# å½“å‰å›žç­”:
{content}

è¯·åˆ†æžè¿™ä¸ªå›žç­”çš„è´¨é‡ï¼ŒæŒ‡å‡ºä¸è¶³ä¹‹å¤„ï¼Œå¹¶æå‡ºå…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚
å¦‚æžœå›žç­”å·²ç»å¾ˆå¥½ï¼Œè¯·å›žç­”"æ— éœ€æ”¹è¿›"ã€‚
""",
    "refine": """
è¯·æ ¹æ®åé¦ˆæ„è§æ”¹è¿›ä½ çš„å›žç­”:

# åŽŸå§‹ä»»åŠ¡:
{task}

# ä¸Šä¸€è½®å›žç­”:
{last_attempt}

# åé¦ˆæ„è§:
{feedback}

è¯·æä¾›ä¸€ä¸ªæ”¹è¿›åŽçš„å›žç­”ã€‚
"""
}



"""
    ç®€å•çš„çŸ­æœŸè®°å¿†æ¨¡å—ï¼Œç”¨äºŽå­˜å‚¨æ™ºèƒ½ä½“çš„è¡ŒåŠ¨ä¸Žåæ€è½¨è¿¹ã€‚
"""
class Memory:
    def __init__(self):
        self.records: List[Dict[str, Any]] = [];


    # å‘è®°å¿†ä¸­æ·»åŠ ä¸€æ¡æ–°çš„è®°å½•
    def add_record(self, record_type:str, content: str):
        self.records.append({"type": record_type, "content": content});
        logger.info(f"ðŸ“ è®°å¿†å·²æ›´æ–°ï¼Œæ–°å¢žä¸€æ¡ '{record_type}' è®°å½•ã€‚")

    """å°†æ‰€æœ‰è®°å¿†è®°å½•æ ¼å¼åŒ–ä¸ºä¸€ä¸ªè¿žè´¯çš„å­—ç¬¦ä¸²æ–‡æœ¬"""
    def get_trajectory(self) -> str:
        
        trajectory = ""
        for record in self.records:
            if record['type'] == 'execution':
                trajectory += f"--- ä¸Šä¸€è½®å°è¯• (ä»£ç ) ---\n{record['content']}\n\n"
            elif record['type'] == 'reflection':
                trajectory += f"--- è¯„å®¡å‘˜åé¦ˆ ---\n{record['content']}\n\n"
        return trajectory.strip()

    def get_last_execution(self) -> str:
        """èŽ·å–æœ€è¿‘ä¸€æ¬¡çš„æ‰§è¡Œç»“æžœ"""
        for record in reversed(self.records):
            if record['type'] == 'execution':
                return record['content']
        return ""
    
"""
Reflection Agent - è‡ªæˆ‘åæ€ä¸Žè¿­ä»£ä¼˜åŒ–çš„æ™ºèƒ½ä½“

è¿™ä¸ªAgentèƒ½å¤Ÿï¼š
1. æ‰§è¡Œåˆå§‹ä»»åŠ¡
2. å¯¹ç»“æžœè¿›è¡Œè‡ªæˆ‘åæ€
3. æ ¹æ®åæ€ç»“æžœè¿›è¡Œä¼˜åŒ–
4. è¿­ä»£æ”¹è¿›ç›´åˆ°æ»¡æ„

ç‰¹åˆ«é€‚åˆä»£ç ç”Ÿæˆã€æ–‡æ¡£å†™ä½œã€åˆ†æžæŠ¥å‘Šç­‰éœ€è¦è¿­ä»£ä¼˜åŒ–çš„ä»»åŠ¡ã€‚

æ”¯æŒå¤šç§ä¸“ä¸šé¢†åŸŸçš„æç¤ºè¯æ¨¡æ¿ï¼Œç”¨æˆ·å¯ä»¥è‡ªå®šä¹‰æˆ–ä½¿ç”¨å†…ç½®æ¨¡æ¿ã€‚
"""
class ReflectionAgent(Agent):


    """
        åˆå§‹åŒ–ReflectionAgent

        Args:
            name: Agentåç§°
            llm: LLMå®žä¾‹
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            config: é…ç½®å¯¹è±¡
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            custom_prompts: è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿ {"initial": "", "reflect": "", "refine": ""}
    """
    def __init__(self, name:str, llm: LlmClient, system_prompt: Optional[str]  = None, config: Optional[Config] = None, max_iterations: int =10, custom_prompts: Optional[Dict[str, str]] = None):
        super().__init__(name, llm, system_prompt, config)
        self.max_iterations = max_iterations;
        self.memory = Memory();

        # è®¾ç½®æç¤ºè¯æ¨¡æ¿ï¼šç”¨æˆ·è‡ªå®šä¹‰ä¼˜å…ˆï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤æ¨¡æ¿
        self.prompts = custom_prompts if custom_prompts else DEFAULT_PROMPTS
    """
    è¿è¡ŒReflection Agent

    Args:
        input_text: ä»»åŠ¡æè¿°
        **kwargs: å…¶ä»–å‚æ•°

    Returns:
        æœ€ç»ˆä¼˜åŒ–åŽçš„ç»“æžœ
    """
    def run(self, input_text:str, **kwargs) ->str:

        logger.info(f"\nðŸ¤– {self.name} å¼€å§‹å¤„ç†ä»»åŠ¡: {input_text}")
        # é‡ç½®è®°å¿†
        self.memory = Memory();

        # 1. åˆå§‹æ‰§è¡Œ
        logger.info("\n--- æ­£åœ¨è¿›è¡Œåˆå§‹å°è¯• ---")
        initial_prompt = self.prompts["initial"].format(task=input_text);
        initial_result = self._get_llm_response(initial_prompt, **kwargs);
        self.memory.add_record("execution", initial_result);
    
        # 2. è¿­ä»£å¾ªçŽ¯: åæ€ä¸Žä¼˜åŒ–
        for i in range(self.max_iterations):
            logger.info(f"\n--- ç¬¬ {i+1}/{self.max_iterations} è½®è¿­ä»£ ---");

            # a. åæ€
            logger.info("\n-> æ­£åœ¨è¿›è¡Œåæ€...")
            last_result = self.memory.get_last_execution();
            reflect_prompt = self.prompts["reflect"].format(
                task=input_text,
                content = last_result,
            )

            feedback = self._get_llm_response(reflect_prompt, **kwargs);
            self.memory.add_record("reflection", feedback);
    
            # b . æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
            if "æ— éœ€æ”¹è¿›" in feedback or "no need for improvement" in feedback.lower():
                logger.info("\nâœ… åæ€è®¤ä¸ºç»“æžœå·²æ— éœ€æ”¹è¿›ï¼Œä»»åŠ¡å®Œæˆã€‚")
                break

            # c. ä¼˜åŒ–
            logger.info("\n-> æ­£åœ¨è¿›è¡Œä¼˜åŒ–...");
            reflect_prompt = self.prompts["refine"].format(
                task=input_text,
                last_attempt=last_result,
                feedback=feedback,
            )

            refined_result = self._get_llm_response(reflect_prompt, **kwargs);
            self.memory.add_record("execution", refined_result);
    
        final_result = self.memory.get_last_execution();
        logger.info(f"\n--- ä»»åŠ¡å®Œæˆ ---\næœ€ç»ˆç»“æžœ:\n{final_result}");

        #ä¿å­˜åˆ°åŽ†å²è®°å½•
        self.add_message(Message(input_text, "user"));
        self.add_message(Message(final_result, "assistant"));
    
        return final_result;



    """
    è°ƒç”¨LLMå¹¶èŽ·å–å®Œæ•´å“åº”
    """
    def _get_llm_response(self, prompt:str, **kwargs) -> str:
        messages = [{"role": "user", "content": prompt}];
        return self.llm.invoke(messages, **kwargs);


